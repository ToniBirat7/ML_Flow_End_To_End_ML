{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d877b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 09:22:15.381674: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-25 09:22:15.482646: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-25 09:22:15.565430: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748144235.637000    6846 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748144235.656481    6846 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748144235.819892    6846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748144235.819928    6846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748144235.819930    6846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748144235.819933    6846 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-25 09:22:15.837898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6672a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Wine Data\n",
    "\n",
    "data = pd.read_csv(\n",
    "  'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',\n",
    "  sep=';'\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95630968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>7.1</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.49</td>\n",
       "      <td>6.50</td>\n",
       "      <td>0.041</td>\n",
       "      <td>28.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99260</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.58</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.24</td>\n",
       "      <td>6.30</td>\n",
       "      <td>0.054</td>\n",
       "      <td>34.0</td>\n",
       "      <td>231.0</td>\n",
       "      <td>0.99640</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4152</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15.00</td>\n",
       "      <td>0.055</td>\n",
       "      <td>8.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.99767</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3932</th>\n",
       "      <td>6.9</td>\n",
       "      <td>0.220</td>\n",
       "      <td>0.28</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.050</td>\n",
       "      <td>43.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>0.99326</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3321</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.33</td>\n",
       "      <td>4.35</td>\n",
       "      <td>0.040</td>\n",
       "      <td>15.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.98934</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.50</td>\n",
       "      <td>12.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.28</td>\n",
       "      <td>6.90</td>\n",
       "      <td>0.036</td>\n",
       "      <td>46.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99299</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.035</td>\n",
       "      <td>45.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.98949</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.36</td>\n",
       "      <td>12.6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>5.7</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.27</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.040</td>\n",
       "      <td>24.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.99411</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.31</td>\n",
       "      <td>10.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.28</td>\n",
       "      <td>9.60</td>\n",
       "      <td>0.051</td>\n",
       "      <td>26.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.12</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.061</td>\n",
       "      <td>27.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>0.99380</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1632            7.1             0.280         0.49            6.50      0.041   \n",
       "1827            7.3             0.190         0.24            6.30      0.054   \n",
       "4152            6.2             0.200         0.25           15.00      0.055   \n",
       "3932            6.9             0.220         0.28            7.80      0.050   \n",
       "3321            6.0             0.260         0.33            4.35      0.040   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "3727            5.7             0.265         0.28            6.90      0.036   \n",
       "4169            6.7             0.210         0.34            1.50      0.035   \n",
       "4133            5.7             0.250         0.27           11.50      0.040   \n",
       "382             7.5             0.350         0.28            9.60      0.051   \n",
       "1442            8.0             0.250         0.49            1.20      0.061   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1632                 28.0                 111.0  0.99260  3.41       0.58   \n",
       "1827                 34.0                 231.0  0.99640  3.36       0.54   \n",
       "4152                  8.0                 120.0  0.99767  3.19       0.53   \n",
       "3932                 43.0                 116.0  0.99326  3.22       0.60   \n",
       "3321                 15.0                  80.0  0.98934  3.29       0.50   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "3727                 46.0                 150.0  0.99299  3.36       0.44   \n",
       "4169                 45.0                 123.0  0.98949  3.24       0.36   \n",
       "4133                 24.0                 120.0  0.99411  3.33       0.31   \n",
       "382                  26.0                 157.0  0.99690  3.12       0.53   \n",
       "1442                 27.0                 117.0  0.99380  3.08       0.34   \n",
       "\n",
       "      alcohol  quality  \n",
       "1632     12.2        8  \n",
       "1827     10.0        6  \n",
       "4152      9.6        6  \n",
       "3932     11.5        8  \n",
       "3321     12.7        6  \n",
       "...       ...      ...  \n",
       "3727     10.8        7  \n",
       "4169     12.6        7  \n",
       "4133     10.8        6  \n",
       "382       9.2        6  \n",
       "1442      9.4        5  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test\n",
    "\n",
    "train,test = train_test_split(data, test_size=0.25)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea7dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['quality'],axis=1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "\n",
    "# Test Data\n",
    "test_x = train.drop(['quality'],axis=1).values\n",
    "test_y = train[['quality']].values.ravel()\n",
    "\n",
    "# Validation after splitting the Training Data\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(train_x,train_y,test_size=0.20,random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3460e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "  \n",
    "\t# Noramlization \n",
    "\tmean = np.mean(train_x,axis=0) # Mean of each col\n",
    "\tvar = np.var(train_x,axis=0) # Var of Each col\n",
    "\n",
    "\tmodel = keras.Sequential(\n",
    "\t\t[\n",
    "\t\t\tkeras.Input([train_x.shape[1]]),\n",
    "\t\t\tkeras.layers.Normalization(mean=mean,variance=var),\n",
    "\t\t\tkeras.layers.Dense(64,activation='relu'),\n",
    "\t\t\tkeras.layers.Dense(1) # Classification\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\t# Model Compile\n",
    "\tmodel.compile(optimizer=keras.optimizers.SGD(\n",
    "\t\tlearning_rate=params['lr'],momentum=params[\"momentum\"]\n",
    "\t),\n",
    "\tloss=\"mean_squared_error\",\n",
    "\tmetrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\t# Train and Track the Hyperparam with MLFlow tracking\n",
    "\n",
    "\twith mlflow.start_run(nested=True): # As we are trying with multiple combination, nested = True\n",
    "\t\tmodel.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tbatch_size=64)\n",
    "\t\t\n",
    "\t\t# Evaluate the model\n",
    "\t\teval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n",
    "\n",
    "\t\teval_rmse = eval_result[1]\n",
    "\n",
    "\t\t# Log the params\n",
    "\t\tmlflow.log_param(\"learning_rate\",params)\n",
    "\t\tmlflow.log_metric(\"Eval Rms\", eval_rmse)\n",
    "\n",
    "\t\t# Log the model\n",
    "\t\tmlflow.tensorflow.log_model(\n",
    "\t\t\tmodel, \n",
    "\t\t\t\"model\",\n",
    "\t\t\tsignature=signature\n",
    "\t\t)\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'loss': eval_rmse,\n",
    "\t\t\t'status': STATUS_OK,\n",
    "\t\t\t'model': model\n",
    "\t\t}\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e8cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function for Hyperopt\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "  # MlFlow will track the params and results for each run\n",
    "\n",
    "  result = train_model(\n",
    "    params, \n",
    "    epochs=3, \n",
    "    train_x=train_x, \n",
    "    train_y=train_y, \n",
    "    valid_x=valid_x, \n",
    "    valid_y=valid_y, \n",
    "    test_x=test_x, \n",
    "    test_y=test_y\n",
    "  )\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70c48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the parameters\n",
    "\n",
    "space = {\n",
    " 'lr': hp.loguniform('lr',np.log(1e-5),np.log(1e-1)),\n",
    " 'momentum': hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31208229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 273ms/step - loss: 39.7355 - root_mean_squared_error: 6.3036\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 14.5992 - root_mean_squared_error: 3.6582 - val_loss: 1.4611 - val_root_mean_squared_error: 1.2087\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.0166 - root_mean_squared_error: 1.0083\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1347 - root_mean_squared_error: 1.0648 - val_loss: 1.0118 - val_root_mean_squared_error: 1.0059\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1350 - root_mean_squared_error: 1.0654\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.9394 - root_mean_squared_error: 0.9683 - val_loss: 0.7902 - val_root_mean_squared_error: 0.8890\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.6939 - root_mean_squared_error: 0.8330\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7527 - root_mean_squared_error: 0.8669 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 323ms/step - loss: 34.0675 - root_mean_squared_error: 5.8367\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 13.2394 - root_mean_squared_error: 3.5183 - val_loss: 2.2109 - val_root_mean_squared_error: 1.4869\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 1.1535 - root_mean_squared_error: 1.0740\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6947 - root_mean_squared_error: 1.3010 - val_loss: 1.6331 - val_root_mean_squared_error: 1.2779\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 1.1304 - root_mean_squared_error: 1.0632\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3585 - root_mean_squared_error: 1.1654 - val_loss: 1.3076 - val_root_mean_squared_error: 1.1435\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.3740 - root_mean_squared_error: 1.1722\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.2774 - root_mean_squared_error: 1.1295 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 318ms/step - loss: 33.4328 - root_mean_squared_error: 5.7821\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 8.2615 - root_mean_squared_error: 2.7180 - val_loss: 1.4510 - val_root_mean_squared_error: 1.2046\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.9882 - root_mean_squared_error: 0.9941\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0616 - root_mean_squared_error: 1.0299 - val_loss: 1.0706 - val_root_mean_squared_error: 1.0347\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: 0.5722 - root_mean_squared_error: 0.7564\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7922 - root_mean_squared_error: 0.8897 - val_loss: 0.8308 - val_root_mean_squared_error: 0.9115\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.7027 - root_mean_squared_error: 0.8383\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8009 - root_mean_squared_error: 0.8931 \n",
      "\n",
      "Epoch 1/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 301ms/step - loss: 35.3798 - root_mean_squared_error: 5.9481\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 13.3681 - root_mean_squared_error: 3.5131 - val_loss: 1.7632 - val_root_mean_squared_error: 1.3279\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 1.1720 - root_mean_squared_error: 1.0826\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.3860 - root_mean_squared_error: 1.1770 - val_loss: 1.2786 - val_root_mean_squared_error: 1.1307\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.9851 - root_mean_squared_error: 0.9925\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1139 - root_mean_squared_error: 1.0542 - val_loss: 1.0296 - val_root_mean_squared_error: 1.0147\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.0938 - root_mean_squared_error: 1.0458\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.0324 - root_mean_squared_error: 1.0151 \n",
      "\n",
      "100%|██████████| 4/4 [00:25<00:00,  6.31s/trial, best loss: 0.888954222202301]\n",
      "[{'loss': 0.888954222202301, 'status': 'ok', 'model': <Sequential name=sequential_8, built=True>}, {'loss': 1.1435121297836304, 'status': 'ok', 'model': <Sequential name=sequential_9, built=True>}, {'loss': 0.9114917516708374, 'status': 'ok', 'model': <Sequential name=sequential_10, built=True>}, {'loss': 1.0146821737289429, 'status': 'ok', 'model': <Sequential name=sequential_11, built=True>}]\n",
      "Best Param: {'lr': np.float64(0.003008777641095085), 'momentum': np.float64(0.854985287842654)}\n",
      "Best Eval EMSE: 0.888954222202301\n"
     ]
    }
   ],
   "source": [
    "# Set Exp\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "\n",
    "# Create another run so that the nested run will work\n",
    "with mlflow.start_run():\n",
    "\n",
    "  # Conduct Hyperparameter search using Hyperopt\n",
    "  trails = Trials()\n",
    "  best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=4,\n",
    "    trials=trails\n",
    "  )\n",
    "\n",
    "  # Fetch the details of the best run\n",
    "  best_run = sorted(trails.results, key=lambda x:x['loss'])[0]\n",
    "\n",
    "  print(trails.results)\n",
    "\n",
    "  # Log the best parameters, loss and model\n",
    "  for key, value in best.items():\n",
    "    mlflow.log_param(key, value)\n",
    "    \n",
    "  mlflow.log_metric(\"Eval_RMSE\", best_run['loss'])\n",
    "  mlflow.tensorflow.log_model(\n",
    "    best_run['model'],\n",
    "    \"model\",\n",
    "    signature=signature,\n",
    "  )\n",
    "\n",
    "  # Print out the best params and loss\n",
    "  print(f\"Best Param: {best}\")\n",
    "  print(f\"Best Eval EMSE: {best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646b2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m115/115\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 546us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[5.2149525],\n",
       "       [4.7655883],\n",
       "       [4.4918528],\n",
       "       ...,\n",
       "       [3.6667314],\n",
       "       [3.1362183],\n",
       "       [3.8509052]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inferencing Model\n",
    "\n",
    "import mlflow\n",
    "\n",
    "model_uri = 'runs:/d6afa02fdf47443bb97a85e0068fd121/model'\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "predictions = loaded_model.predict(test_x)\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
