{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d877b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-25 00:33:11.732286: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-25 00:33:11.735430: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-05-25 00:33:11.743088: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748112491.755811  388683 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748112491.759372  388683 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748112491.770383  388683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748112491.770402  388683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748112491.770403  388683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748112491.770405  388683 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-25 00:33:11.774107: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6672a26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data Wine Data\n",
    "\n",
    "data = pd.read_csv(\n",
    "  'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-white.csv',\n",
    "  sep=';'\n",
    ")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95630968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.037</td>\n",
       "      <td>39.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.99310</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.46</td>\n",
       "      <td>10.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4007</th>\n",
       "      <td>6.4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.57</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.062</td>\n",
       "      <td>21.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>0.99238</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.039</td>\n",
       "      <td>13.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99150</td>\n",
       "      <td>3.05</td>\n",
       "      <td>0.49</td>\n",
       "      <td>10.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.043</td>\n",
       "      <td>46.0</td>\n",
       "      <td>238.0</td>\n",
       "      <td>0.99860</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.41</td>\n",
       "      <td>8.7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.30</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.035</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.41</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4129</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.31</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.020</td>\n",
       "      <td>18.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.98981</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.29</td>\n",
       "      <td>13.4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>8.2</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.039</td>\n",
       "      <td>49.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.99760</td>\n",
       "      <td>3.31</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>6.7</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.34</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.049</td>\n",
       "      <td>29.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.22</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4155</th>\n",
       "      <td>6.1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.47</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>50.0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.99270</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>7.6</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.28</td>\n",
       "      <td>10.4</td>\n",
       "      <td>0.049</td>\n",
       "      <td>57.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>0.99748</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.45</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3673 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "636             6.2              0.17         0.28             4.7      0.037   \n",
       "4007            6.4              0.25         0.57             1.0      0.062   \n",
       "898             6.6              0.26         0.29             1.4      0.039   \n",
       "1230            7.3              0.29         0.30            13.0      0.043   \n",
       "256             6.3              0.35         0.30             5.7      0.035   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4129            6.3              0.34         0.31             6.0      0.020   \n",
       "232             8.2              0.27         0.39             7.8      0.039   \n",
       "113             6.7              0.41         0.34             9.2      0.049   \n",
       "4155            6.1              0.30         0.47             1.4      0.049   \n",
       "2260            7.6              0.48         0.28            10.4      0.049   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "636                  39.0                 133.0  0.99310  3.41       0.46   \n",
       "4007                 21.0                 122.0  0.99238  3.00       0.40   \n",
       "898                  13.0                  67.0  0.99150  3.05       0.49   \n",
       "1230                 46.0                 238.0  0.99860  3.06       0.41   \n",
       "256                   8.0                  97.0  0.99270  3.27       0.41   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4129                 18.0                  68.0  0.98981  3.22       0.29   \n",
       "232                  49.0                 208.0  0.99760  3.31       0.51   \n",
       "113                  29.0                 150.0  0.99680  3.22       0.51   \n",
       "4155                 50.0                 187.0  0.99270  3.19       0.45   \n",
       "2260                 57.0                 205.0  0.99748  3.24       0.45   \n",
       "\n",
       "      alcohol  quality  \n",
       "636      10.8        7  \n",
       "4007      9.5        5  \n",
       "898      10.9        6  \n",
       "1230      8.7        6  \n",
       "256      11.0        7  \n",
       "...       ...      ...  \n",
       "4129     13.4        7  \n",
       "232       9.5        6  \n",
       "113       9.1        5  \n",
       "4155      9.5        5  \n",
       "2260      9.3        5  \n",
       "\n",
       "[3673 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train Test\n",
    "\n",
    "train,test = train_test_split(data, test_size=0.25)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ea7dfc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['quality'],axis=1).values\n",
    "train_y = train[['quality']].values.ravel()\n",
    "\n",
    "# Test Data\n",
    "test_x = train.drop(['quality'],axis=1).values\n",
    "test_y = train[['quality']].values.ravel()\n",
    "\n",
    "# Validation after splitting the Training Data\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(train_x,train_y,test_size=0.20,random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3460e082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANN Model\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "def train_model(params, epochs, train_x, train_y, valid_x, valid_y, test_x, test_y):\n",
    "  \n",
    "\t# Noramlization \n",
    "\tmean = np.mean(train_x,axis=0) # Mean of each col\n",
    "\tvar = np.var(train_x,axis=0) # Var of Each col\n",
    "\n",
    "\tmodel = keras.Sequential(\n",
    "\t\t[\n",
    "\t\t\tkeras.Input([train_x.shape[1]]),\n",
    "\t\t\tkeras.layers.Normalization(mean=mean,variance=var),\n",
    "\t\t\tkeras.layers.Dense(64,activation='relu'),\n",
    "\t\t\tkeras.layers.Dense(1) # Classification\n",
    "\t\t]\n",
    "\t)\n",
    "\n",
    "\t# Model Compile\n",
    "\tmodel.compile(optimizer=keras.optimizers.SGD(\n",
    "\t\tlearning_rate=params['lr'],momentum=params[\"momentum\"]\n",
    "\t),\n",
    "\tloss=\"mean_squared_error\",\n",
    "\tmetrics=[keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "\t# Train and Track the Hyperparam with MLFlow tracking\n",
    "\n",
    "\twith mlflow.start_run(nested=True): # As we are trying with multiple combination, nested = True\n",
    "\t\tmodel.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "\t\t\t\t\t\tepochs=epochs,\n",
    "\t\t\t\t\t\tbatch_size=64)\n",
    "\t\t\n",
    "\t\t# Evaluate the model\n",
    "\t\teval_result = model.evaluate(valid_x, valid_y, batch_size=64)\n",
    "\n",
    "\t\teval_rmse = eval_result[1]\n",
    "\n",
    "\t\t# Log the params\n",
    "\t\tmlflow.log_param(\"learning_rate\",params)\n",
    "\t\tmlflow.log_metric(\"Eval Rms\", eval_rmse)\n",
    "\n",
    "\t\t# Log the model\n",
    "\t\tmlflow.tensorflow.log_model(\n",
    "\t\t\tmodel, \n",
    "\t\t\t\"model\",\n",
    "\t\t\tsignature=signature\n",
    "\t\t)\n",
    "\n",
    "\t\treturn {\n",
    "\t\t\t'loss': eval_rmse,\n",
    "\t\t\t'status': STATUS_OK,\n",
    "\t\t\t'model': model\n",
    "\t\t}\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8e8cdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective Function for Hyperopt\n",
    "\n",
    "def objective(params):\n",
    "\n",
    "  # MlFlow will track the params and results for each run\n",
    "\n",
    "  result = train_model(\n",
    "    params, \n",
    "    epochs=3, \n",
    "    train_x=train_x, \n",
    "    train_y=train_y, \n",
    "    valid_x=valid_x, \n",
    "    valid_y=valid_y, \n",
    "    test_x=test_x, \n",
    "    test_y=test_y\n",
    "  )\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70c48fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the parameters\n",
    "\n",
    "space = {\n",
    " 'lr': hp.loguniform('lr',np.log(1e-5),np.log(1e-1)),\n",
    " 'momentum': hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31208229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 257ms/step - loss: 40.9917 - root_mean_squared_error: 6.4025\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 11.8577 - root_mean_squared_error: 3.2641 - val_loss: 1.1789 - val_root_mean_squared_error: 1.0858\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 1.3884 - root_mean_squared_error: 1.1783\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.1243 - root_mean_squared_error: 1.0601 - val_loss: 0.8332 - val_root_mean_squared_error: 0.9128\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.0121 - root_mean_squared_error: 1.0060\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8429 - root_mean_squared_error: 0.9169 - val_loss: 0.6900 - val_root_mean_squared_error: 0.8306\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.8868 - root_mean_squared_error: 0.9417\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.7292 - root_mean_squared_error: 0.8534 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 270ms/step - loss: 31.3316 - root_mean_squared_error: 5.5975\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.3777 - root_mean_squared_error: 2.3669 - val_loss: 0.8591 - val_root_mean_squared_error: 0.9269\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.1605 - root_mean_squared_error: 1.0772\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.9002 - root_mean_squared_error: 0.9475 - val_loss: 0.6642 - val_root_mean_squared_error: 0.8150\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.9634 - root_mean_squared_error: 0.9815\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6453 - root_mean_squared_error: 0.8023 - val_loss: 0.5825 - val_root_mean_squared_error: 0.7632\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7620 - root_mean_squared_error: 0.8729\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6157 - root_mean_squared_error: 0.7841 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 278ms/step - loss: 35.3339 - root_mean_squared_error: 5.9442\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 6.4574 - root_mean_squared_error: 2.3677 - val_loss: 0.8914 - val_root_mean_squared_error: 0.9441\n",
      "\n",
      "Epoch 2/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 1.0549 - root_mean_squared_error: 1.0271\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.8767 - root_mean_squared_error: 0.9345 - val_loss: 0.6178 - val_root_mean_squared_error: 0.7860\n",
      "\n",
      "Epoch 3/3                                                                     \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.8086 - root_mean_squared_error: 0.8992\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.5961 - root_mean_squared_error: 0.7717 - val_loss: 0.5536 - val_root_mean_squared_error: 0.7440\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.7960 - root_mean_squared_error: 0.8922\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.6008 - root_mean_squared_error: 0.7741 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 277ms/step - loss: 33.3044 - root_mean_squared_error: 5.7710\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 22.1954 - root_mean_squared_error: 4.6621 - val_loss: 3.2973 - val_root_mean_squared_error: 1.8158\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3.6969 - root_mean_squared_error: 1.9227\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0633 - root_mean_squared_error: 1.7485 - val_loss: 2.0047 - val_root_mean_squared_error: 1.4159\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/46\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2.0628 - root_mean_squared_error: 1.4363\n",
      "\u001b[1m46/46\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.2634 - root_mean_squared_error: 1.5041 - val_loss: 1.6547 - val_root_mean_squared_error: 1.2864\n",
      "\n",
      "\u001b[1m 1/12\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.9826 - root_mean_squared_error: 1.4080\n",
      "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.7057 - root_mean_squared_error: 1.3053 \n",
      "\n",
      "100%|██████████| 4/4 [00:23<00:00,  5.79s/trial, best loss: 0.7440405488014221]\n",
      "Best Param: {'lr': np.float64(0.03773849124318459), 'momentum': np.float64(0.02367077315939181)}\n",
      "Best Eval EMSE: 0.7440405488014221\n"
     ]
    }
   ],
   "source": [
    "# Set Exp\n",
    "\n",
    "import mlflow.tensorflow\n",
    "\n",
    "\n",
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "\n",
    "# Create another run so that the nested run will work\n",
    "with mlflow.start_run():\n",
    "\n",
    "  # Conduct Hyperparameter search using Hyperopt\n",
    "  trails = Trials()\n",
    "  best = fmin(\n",
    "    fn=objective,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=4,\n",
    "    trials=trails\n",
    "  )\n",
    "\n",
    "  # Fetch the details of the best run\n",
    "  best_run = sorted(trails.results, key=lambda x:x['loss'])[0]\n",
    "\n",
    "  # Log the best parameters, loss and model\n",
    "  for key, value in best.items():\n",
    "    mlflow.log_param(key, value)\n",
    "  mlflow.log_metric(\"Eval_RMSE\", best_run['loss'])\n",
    "  mlflow.tensorflow.log_model(\n",
    "    best_run['model'],\n",
    "    \"model\",\n",
    "    signature=signature\n",
    "  )\n",
    "\n",
    "  # Print out the best params and loss\n",
    "  print(f\"Best Param: {best}\")\n",
    "  print(f\"Best Eval EMSE: {best_run['loss']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
