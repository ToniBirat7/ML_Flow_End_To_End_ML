{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eae0d8b",
   "metadata": {},
   "source": [
    "## **Working of with Keyowrd**\n",
    "\n",
    "[GPT_Explanation](https://chatgpt.com/share/681f4657-6520-8006-b695-a215a1783899)\n",
    "\n",
    "[Real_Python_Implementation](https://www.youtube.com/watch?v=iba-I4CrmyA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3429f5bc",
   "metadata": {},
   "source": [
    "## **Before Starting Project**\n",
    "\n",
    "`source mlflow_env/bin/activate`\n",
    "\n",
    "`mlflow ui`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a79da5f",
   "metadata": {},
   "source": [
    "## **ML Flow**\n",
    "\n",
    "Open-source. We can track our Machine Learning project such as performance metrices etc.\n",
    "\n",
    "## **Lifecycle of a Data Science Project**\n",
    "\n",
    "**Data Pre**\n",
    "\n",
    "**EDA**\n",
    "\n",
    "**Feature Eng**\n",
    "\n",
    "**Model Training**\n",
    "\n",
    "**Model Validation**\n",
    "\n",
    "**Deployment**\n",
    "\n",
    "**Monitoring**\n",
    "\n",
    "## **How ML Flow is used by Data Scientist**\n",
    "\n",
    "- Experiment Tracking\n",
    "\n",
    "- Hypothesis Testing in EDA\n",
    "\n",
    "- Code Structuring (Pipeline)\n",
    "\n",
    "- Model Packaging and Dependency Management\n",
    "\n",
    "- Evaluating Hyperparameter : Track every combination of Hyperparameter\n",
    "\n",
    "- Compare the results of model and deploy the best performing model\n",
    "\n",
    "## **How ML Flow is used by ML Engineeer**\n",
    "\n",
    "- Manage the lifecycle of trained models both pre and post deployment\n",
    "\n",
    "- Deploy models security to the production env\n",
    "\n",
    "- Manage Deployment Dependencies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d72f24",
   "metadata": {},
   "source": [
    "## **ML Flow Starter**\n",
    "\n",
    "### **ML Flow Tracking Server**\n",
    "\n",
    "For tracking our experiments we need to create a server\n",
    "\n",
    "To start the server we use `mlflow ui`.\n",
    "\n",
    "Then we will need to provide the tracking UI so that everything is tracked by MLFlow. `mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")`\n",
    "\n",
    "Then to log our performance metrices we will use as below:\n",
    "\n",
    "```py\n",
    "\n",
    "mlflow.set_experiment(\"Day2\")\n",
    "\n",
    "# Start the MLFlow Run\n",
    "\n",
    "with mlflow.start_run():\n",
    "  # Log the hyperparameters\n",
    "  mlflow.log_params(params)\n",
    "\n",
    "\t# Log te accuracy metrics\n",
    "  mlflow.log_metric(\"Accuracy\",accuracy)\n",
    "\n",
    "\t# Set tag that we can use to remind ourselves what this run was for\n",
    "  mlflow.set_tag(\"Training Info\", \"Basic LR Model for Iris Data\")\n",
    "\n",
    "\t# Infer the model signature\n",
    "  signature = infer_signature(x_train, model.predict(x_train))\n",
    "\n",
    "\t# Log the model\n",
    "  model_info = mlflow.sklearn.log_model(\n",
    "    sk_model=model,\n",
    "    artifact_path=\"Iris Mode\",\n",
    "    signature = signature,\n",
    "    input_example=x_train,\n",
    "    registered_model_name=\"Tracking-quickstart\"\n",
    "\t)\n",
    "\n",
    "```\n",
    "\n",
    "A new folder named `mlruns` is created which stores all the info about our experiments. We should not delete the `mlruns` folder.\n",
    "\n",
    "## **Tracking a ML Project with MLFlow**\n",
    "\n",
    "`project.ipynb`\n",
    "\n",
    "Let's create a sparate folder for our ML Project.\n",
    "\n",
    "Once we have setup our ML Project, now we will have to keep track of different performance metrics on the basis of our used hyperparameters. For which we will use `ML Flow`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089fb6bf",
   "metadata": {},
   "source": [
    "## **Inference of Model Artifacts**\n",
    "\n",
    "### **UI**\n",
    "\n",
    "`path` : Path of artifacts\n",
    "\n",
    "**Validate Before Deployment**\n",
    "\n",
    "As soon as we complete training our model, the model is saved as `model.pkl` in the `artifacts` but before using the model in the production we will need to validate it.\n",
    "\n",
    "For that the base code already provided in the UI only.\n",
    "\n",
    "```Py\n",
    "\n",
    "# Validate The Model\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import Model\n",
    "\n",
    "model_uri = 'runs:/cd866b98bcfb4235bbe3b225ece9fce9/Iris Mode'\n",
    "# The model is logged with an input example\n",
    "pyfunc_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "predictions = pyfunc_model.predict(x_test)\n",
    "\n",
    "predictions\n",
    "\n",
    "```\n",
    "\n",
    "`mlflow.pyfunc.load_model` loads the model as `Python's` generic function.\n",
    "\n",
    "## **Model Registry Tracking**\n",
    "\n",
    "Model Registry is a centralized model store, set of APIs, and UI to collaboratively manage the full lifecycke of an MLFlow Model. It provides model lineage (which MLFlow exps and runs produced the model), model versioning, model aliasing, model tagging and annotations.\n",
    "\n",
    "In the previous code, we directly saved (Registerd) the model without even validating if it the best model. As we provided `registered_model_name=\"Tracking-quickstart\"` argument in the `log_model` function which registers and maintains the model versioning.\n",
    "\n",
    "To avoid it we should not pass this parameter. If we not pass this parameter in the `UI` there will be a `Button` as `Register Model`. If the model has been registered then it would be `Model Registered` with it's version.\n",
    "\n",
    "How do we choose the best model? We need to compare the experiments and then find the experiment with the highest accuracy and then register that experiment.\n",
    "\n",
    "Okay, we've saved our best model but how are we going to predict from the saved best model?\n",
    "\n",
    "```Py\n",
    "\n",
    "# Inferencing the Model from the Model Registry (Prediction from the Best Model)\n",
    "\n",
    "# Inferencing the Model from the Model Registry (Prediction from the Best Model)\n",
    "\n",
    "import mlflow.sklearn\n",
    "\n",
    "model_name = 'Tracking-quickstart'\n",
    "model_version = '6' # Version of the best model {latest, number_version, ..}\n",
    "\n",
    "# Path for the model from the Model Registry\n",
    "model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n",
    "model.predict(x_test)\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff5dc54",
   "metadata": {},
   "source": [
    "## **Hosue Price Pred (MLFlow)**\n",
    "\n",
    "Refer to `ML_Project/Phase2(House).ipynb` file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bd2066",
   "metadata": {},
   "source": [
    "## **ANN with MLFlow**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e1d8f0",
   "metadata": {},
   "source": [
    "### **Next Day**\n",
    "\n",
    "**Revise Everything Before Starting**\n",
    "\n",
    "https://www.udemy.com/course/complete-mlops-bootcamp-with-10-end-to-end-ml-projects/learn/lecture/46068371#overview\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
